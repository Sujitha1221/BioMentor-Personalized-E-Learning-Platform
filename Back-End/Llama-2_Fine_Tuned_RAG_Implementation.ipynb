{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\shobi\\anaconda3\\lib\\site-packages (1.9.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: transformers in c:\\users\\shobi\\anaconda3\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\shobi\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\shobi\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shobi\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='llama3': {'name'}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Using the following context:\n",
      "                In human female, after parturition There will be no change in the blood progesterone level of mother Secretion of PIH increases gradually There can be periodic increase of Oestradiol level Degeneration of corpus luteum High level of Oestradiol inhibits secretion of GnRH from pituitary gland Correct statement regarding feedback mechanism of endocrine gland Most of the hormones are regulated by positive feed back Some hormone levels directly regulated by blood level stimuli Signals from hypothalamus to inhibit heat gain are inhibited by positive feed back When temperature rises above normal level, secretion of thyroid hormone is stimulated When blood osmolarity rises beyond normal level, ADH is not secreted  In the order and organizational level of living matter, in which level plant leaf can be placed? Molecule Organ Cell Tissue Organ system\n",
      "\n",
      "                Your task is to generate **single multiple-choice biology question** for the easy level. Ensure the question is clear, concise, and directly related to the provided context. \n",
      "\n",
      "                The format should include:\n",
      "                - One question\n",
      "                - Five answer options labelled as a, b, c, d and e\n",
      "                - Indicate which option is the correct answer.\n",
      "\n",
      "                Do not include example questions or extra text.\n",
      "\n",
      "                Output format:\n",
      "                Question: <Your question here>\n",
      "                a) <Option 1>\n",
      "                b) <Option 2>\n",
      "                c) <Option 3>\n",
      "                d) <Option 4>\n",
      "                e) <Option 5>\n",
      "                Correct Answer: <Correct option letter>\n",
      "                \n",
      "\n",
      "\n",
      "Question: \n",
      "What is the primary function of the hypothalamus in the endocrine system?\n",
      "a) To secrete insulin\n",
      "b) To secrete thyroid hormone\n",
      "c) To regulate blood pressure\n",
      "d) To regulate the secretion of hormones\n",
      "e) To regulate the breakdown of nutrients\n",
      "\n",
      "\n",
      "Correct Answer: d) To regulate the secretion of hormones\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import faiss\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = 'merged_mcq_dataset.csv'  # Update this path to your file\n",
    "dataset = pd.read_csv(file_path, encoding='latin1')  # Use appropriate encoding\n",
    "\n",
    "# Step 2: Fill missing values with an empty string\n",
    "dataset.fillna(\"\", inplace=True)\n",
    "\n",
    "# Step 3: Combine question and options into a single field for context\n",
    "dataset['Combined'] = (\n",
    "    dataset['Question Text'].astype(str) + \" \" +\n",
    "    dataset['Option 1'].astype(str) + \" \" +\n",
    "    dataset['Option 2'].astype(str) + \" \" +\n",
    "    dataset['Option 3'].astype(str) + \" \" +\n",
    "    dataset['Option 4'].astype(str) + \" \" +\n",
    "    dataset['Option 5'].astype(str)\n",
    ")\n",
    "\n",
    "# Step 4: Vectorize the combined text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "vectors = vectorizer.fit_transform(dataset['Combined']).toarray()\n",
    "\n",
    "# Step 5: Create FAISS index\n",
    "dimension = vectors.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(vectors)\n",
    "\n",
    "print(\"FAISS index created successfully!\")\n",
    "\n",
    "# Step 6: Function to retrieve relevant context\n",
    "def retrieve_context(query, k=3):\n",
    "    query_vector = vectorizer.transform([query]).toarray()\n",
    "    _, indices = faiss_index.search(query_vector, k)\n",
    "    return dataset.iloc[indices[0]]\n",
    "\n",
    "# Step 7: Load the language model and tokenizer\n",
    "model_name = \"./saved_model\"  # Update this to your saved model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Step 8: Generate a question using retrieved context\n",
    "def generate_question(query, difficulty=\"easy\"):\n",
    "    # Retrieve relevant context\n",
    "    retrieved_context = retrieve_context(query)\n",
    "    context = \" \".join(retrieved_context['Combined'].tolist())\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"\n",
    "                Using the following context:\n",
    "                {context}\n",
    "\n",
    "                Your task is to generate **single multiple-choice biology question** for the {difficulty} level. Ensure the question is clear, concise, and directly related to the provided context. \n",
    "\n",
    "                The format should include:\n",
    "                - One question\n",
    "                - Five answer options labelled as a, b, c, d and e\n",
    "                - Indicate which option is the correct answer.\n",
    "\n",
    "                Do not include example questions or extra text.\n",
    "\n",
    "                Output format:\n",
    "                Question: <Your question here>\n",
    "                a) <Option 1>\n",
    "                b) <Option 2>\n",
    "                c) <Option 3>\n",
    "                d) <Option 4>\n",
    "                e) <Option 5>\n",
    "                Correct Answer: <Correct option letter>\n",
    "                \"\"\"\n",
    "\n",
    "    # Tokenize prompt and generate response\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    output = model.generate(input_ids, max_length=1000, temperature=0.7, top_k=50)\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "difficulty = \"easy\"\n",
    "query = f\"Generate a biology question for {difficulty} level.\"\n",
    "generated_mcq = generate_question(query, difficulty=difficulty)\n",
    "print(generated_mcq)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
